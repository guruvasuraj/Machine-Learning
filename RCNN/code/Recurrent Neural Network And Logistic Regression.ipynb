{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.special import comb\n",
    "import itertools\n",
    "from collections import Counter \n",
    "from sknn.mlp import Classifier, Convolution, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the file\n",
    "def readFile(fileName):\n",
    "    with open(fileName,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_read = readFile('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Remove non-alphanumeric content from the text \n",
    "'''\n",
    "\n",
    "\n",
    "def stripnonalphanumeric(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    x =  re.sub(r'\\d+', '', text)\n",
    "    y =  re.sub(r'_+', '', x)\n",
    "    return re.findall(r'\\w+', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(sent):\n",
    "    neg_sent=[]\n",
    "    pos_sent=[]\n",
    "    for s in sent:\n",
    "        tab_sep_data = s.split('\\t')\n",
    "        if int(tab_sep_data[1]) == 0:\n",
    "            neg_sent.append(tab_sep_data[0])\n",
    "        else:\n",
    "            pos_sent.append(tab_sep_data[0])\n",
    "    return pos_sent,neg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_sent,neg_sent=split_data(lines_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(pos_sent,neg_sent):\n",
    "    \n",
    "    x=pos_sent+neg_sent\n",
    "    x=[stripnonalphanumeric(s) for s in x]\n",
    "    x=[s.split(' ') for s in x]\n",
    "    pos_lab = [[1,0] for p in pos_sent]\n",
    "    neg_lab = [[0,1] for n in neg_sent]\n",
    "    y=np.concatenate([pos_lab,neg_lab],0)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y=prepare_data(pos_sent,neg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_data(x):\n",
    "    append_word = '!!FILL!!'\n",
    "    max_sent_length = max(len(s) for s in x)\n",
    "    created_data = []\n",
    "    for i in range(len(x)):\n",
    "        sent = x[i]\n",
    "        fills = max_sent_length - len(sent)\n",
    "        n_sent = sent + [append_word] *fills\n",
    "        created_data.append(n_sent)\n",
    "    return created_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pool_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_dict_builder(sent):\n",
    "    w_count = Counter(itertools.chain(*sent))\n",
    "    voc_dict = [x[0] for x in w_count.most_common()]\n",
    "    voc_idx_map = {x: i for i, x in enumerate(voc_dict)}\n",
    "    return [voc_dict,voc_idx_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words,words_idx=vocab_dict_builder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feat_vec(data,words,words_idx):\n",
    "    x=np.array([[words_idx[i] for i in d] for d in data])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=feat_vec(data,words,words_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices].argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_create_data(data):\n",
    "    z = data\n",
    "    for j in z:\n",
    "        j.insert(0,1)   \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i[0] not in class_count1.keys():\n",
    "            class_count1[i[0]] = 1\n",
    "        else:\n",
    "            class_count1[i[0]] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Assumption of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_assume_weights(g,h,n,nc):\n",
    "    s = np.random.randn(g,n)/10000\n",
    "    w = np.random.randn(h,(g+1))/10000\n",
    "    v = (np.random.randn(nc-1,(h+1))-10)/10000\n",
    "    return s,w,v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function of Indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_indicator(y,cl):\n",
    "    ind = np.zeros([len(y),len(cl)])\n",
    "    for k in range(len(cl)):\n",
    "        for l in range(len(y)):\n",
    "            if y[l][0] == cl[k]:\n",
    "                ind[l][k] = 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_find_sigmoid(ws,datas):\n",
    "    sigmoid = []\n",
    "    for ii in datas:\n",
    "        tmp = []\n",
    "        for jj in range(len(ws)):\n",
    "            xz = np.dot(ws[jj].transpose(),ii)\n",
    "            tmp.append(1.0/(1+np.exp(-xz)))\n",
    "        sigmoid.append(tmp)\n",
    "    sigmoid =rec_create_data(sigmoid)\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_find_sigmoid1(ws,datas):\n",
    "    sigmoid = []\n",
    "    for ii in datas:\n",
    "        tmp = []\n",
    "        for jj in range(len(ws)):\n",
    "            xz = np.dot(ws[jj].transpose(),ii)\n",
    "            tmp.append(np.tanh(xz))\n",
    "        sigmoid.append(tmp)\n",
    "    sigmoid =rec_create_data(sigmoid)\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftMax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_softmax(theta,data):\n",
    "    soft = np.zeros([len(data),len(theta)])\n",
    "    for i in range(len(data)):\n",
    "        s = 0\n",
    "        for j in range(len(theta)):\n",
    "            s = s + np.exp(np.dot(theta[j].T,data[i]))\n",
    "        for k in range(len(theta)):\n",
    "            xy = np.exp(np.dot(theta[k].transpose(),data[i]))\n",
    "            soft[i][k] = (xy*1.0)/s\n",
    "    return soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for layer V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputlayer(datam,wm,sm,indic,lr,v):\n",
    "    qy = rec_find_sigmoid1(sm,datam)\n",
    "    zy = rec_find_sigmoid1(wm,qy)\n",
    "    yhat = rec_softmax(v,zy)\n",
    "    for n in range(len(v)):\n",
    "        sumsv = 0\n",
    "        for m in range(len(yhat)):\n",
    "            sumsv = sumsv + np.dot((yhat[m][n] - indic[m][n]) , zy[n])\n",
    "        v[n]= v[n] - (lr*sumsv)\n",
    "    return v,yhat,zy,qy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for layer W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_intrim(yh,y,v,j,k):\n",
    "    sv = 0\n",
    "    for ll in range(len(v)):\n",
    "        xx = yh[k][ll]- y[k][ll]\n",
    "        sv = sv + xx*v[ll][j]\n",
    "    return sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def firstlayer(v,z,yhh,dataq,indic,w,lr):\n",
    "    for j in range(len(w)):\n",
    "        sq = 0\n",
    "        for i in range(len(dataq)):\n",
    "            x = np.dot(rec_intrim(yhh,indic,v,j,i),z[i][j])\n",
    "            y = np.dot((1-z[i][j]),dataq[i])\n",
    "            sq = sq + np.dot(x,y)\n",
    "        w[j] = w[j] - (lr*sq)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Layer S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def secondlayer(v,w,yhh,indic,q,data,s,lr):\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        sums = 0\n",
    "        for l in range(len(data)): \n",
    "            sumw =0\n",
    "            for j in range(len(w)):\n",
    "                sumv = 0\n",
    "                for k in range(len(v)):\n",
    "                    sumv = sumv + np.dot((yhh[l][k]-indic[l][k]),v[k][j])\n",
    "                tmp1 = np.dot((1-w[j][i]),w[j][i])\n",
    "                sumw = sumw + sumv*np.dot(tmp1,q[l][i])\n",
    "            tmp2 = np.dot((1-q[l][i]),q[l][i])\n",
    "            sums = sums + sumw*(np.dot(tmp2,data[l]))\n",
    "        s[i] = s[i] - lr*sums\n",
    "    return s     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Gradient Descent with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_desc(W,V,S,data,indic,lr,ic):\n",
    "    for cnt in range(ic):\n",
    "        V,yh,Z,Q = outputlayer(data,W,S,indic,lr,V)\n",
    "        W1 = firstlayer(V,Z,yh,Q,indic,W,lr)\n",
    "        W = firstlayer(V,Z,yh,Q,indic,W1,lr)\n",
    "        S = secondlayer(V,W1,yh,indic,Q,data,S,lr)\n",
    "    return V,W,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_desc1(W,V,S,data,indic,lr,ic):\n",
    "    for cnt in range(ic):\n",
    "        V,yh,Z,Q = outputlayer(data,W,S,indic,lr,V)\n",
    "        W1 = firstlayer(V,Z,yh,Q,indic,W,lr)\n",
    "        W = firstlayer(V,Z,yh,Q,indic,W1,lr)\n",
    "        W = W + 0.002*W1\n",
    "        S1 = secondlayer(V,W,yh,indic,Q,data,S,lr)\n",
    "        S = secondlayer(V,W1,yh,indic,Q,data,S1,lr)\n",
    "        S = S + 0.002*S1\n",
    "    return V,W,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_train(data,label,g,h,cl,lr,ic):\n",
    "    s0,w0,v0 = rec_assume_weights(g,h,data.shape[1],len(cl))\n",
    "    ind = rec_indicator(label,cl)\n",
    "    Vf,Wf,Sf = grad_desc(w0,v0,s0,data,ind,lr,ic)\n",
    "    return Vf,Wf,Sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rec_prediction(w,v,s,data,cl):\n",
    "    Qp = rec_find_sigmoid1(s,data)\n",
    "    Zp = rec_find_sigmoid1(w,Qp)\n",
    "    pre = rec_softmax(v,Zp)  \n",
    "    ll = []\n",
    "    for j in range(len(pre)):\n",
    "        if pre[j][0] > np.mean(pre):\n",
    "            ll.append([1])\n",
    "        else:\n",
    "            ll.append([0])\n",
    "    return np.array(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j][0] == i and actual[j][0] == predicted[j][0]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j][0] == i and actual[j][0] != predicted[j][0]:\n",
    "                tmp[clabels.index(predicted[j][0])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)\n",
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)\n",
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres\n",
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec\n",
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy = []\n",
    "yl = []\n",
    "for i in y:\n",
    "    if i[0] == 1:\n",
    "        yy.append([1])\n",
    "        yl.append(1)\n",
    "    else:\n",
    "        yy.append([0])\n",
    "        yl.append(0)\n",
    "yy = np.array(yy)\n",
    "yl = np.array(yl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "provide the data,labels,number of featues in S, number of features in W, the classes, Learning rate, iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes,class_count,alpha = rec_find_alpha(yy)\n",
    "Vf,Wf,Sf = rec_train(x,yy,10,10,classes,0.000454,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY =rec_prediction(Wf,Vf,Sf,x,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[283 217]\n",
      " [260 240]]\n",
      "Accuracy 0.523\n",
      "Precision [0.52117863720073665, 0.52516411378555794]\n",
      "Recall [0.56599999999999995, 0.47999999999999998]\n",
      "F_score [0.54266538830297217, 0.5015673981191221]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,yy,YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "provide the data,labels,number of featues in S, number of features in W, the classes, Learning rate, iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vf1,Wf1,Sf1 = rec_train(x,yy,30,30,classes,0.000454,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY1 =rec_prediction(Wf1,Vf1,Sf1,x,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[289 211]\n",
      " [233 267]]\n",
      "Accuracy 0.556\n",
      "Precision [0.55363984674329503, 0.55857740585774063]\n",
      "Recall [0.57799999999999996, 0.53400000000000003]\n",
      "F_score [0.56555772994129161, 0.54601226993865037]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,yy,YY1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "\n",
    "## Recuurent Neural Network with complete features\n",
    "provide the data,labels,number of featues in S, number of features in W, the classes, Learning rate, iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vf2,Wf2,Sf2 = rec_train(x,yy,80,80,classes,0.000454,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY2 =rec_prediction(Wf2,Vf2,Sf2,x,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[500   0]\n",
      " [ 83 417]]\n",
      "Accuracy 0.917\n",
      "Precision [0.85763293310463118, 1.0]\n",
      "Recall [1.0, 0.83399999999999996]\n",
      "F_score [0.92336103416435833, 0.90948745910577966]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,yy,YY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4\n",
    "provide the data,labels,number of featues in S, number of features in W, the classes, Learning rate, iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vf3,Wf3,Sf3 = rec_train(x,yy,20,30,classes,0.0000454,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY3 =rec_prediction(Wf3,Vf3,Sf3,x,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY3 = np.append(YY3,[[0]]*127,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[142 358]\n",
      " [383 117]]\n",
      "Accuracy 0.259\n",
      "Precision [0.27047619047619048, 0.24631578947368421]\n",
      "Recall [0.28399999999999997, 0.23400000000000001]\n",
      "F_score [0.27707317073170729, 0.23999999999999999]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,yy,YY3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "filename = \"imdb_labelled.txt\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "review = []\n",
    "Y = []\n",
    "for i in r:\n",
    "    x = i.split('\\t')\n",
    "    review.append(x[0])\n",
    "    Y.append([float(x[-1])])\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countvectorizer Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix represents 1000 documents with 1441 features\n",
      "first doc has terms:\n",
      "[0, 27, 31, 32, 724, 756, 757, 774, 1019, 1311, 1316, 1438]\n"
     ]
    }
   ],
   "source": [
    "def count_vectorize(filenames, tokenizer_fn=tokenize, min_df=3,\n",
    "                 max_df=.8, binary=True, ngram_range=(1,3)):\n",
    "   \n",
    "    vectorizer = CountVectorizer(tokenizer = tokenizer_fn, min_df=min_df, \n",
    "                                     max_df=max_df, binary=binary, ngram_range=ngram_range, \n",
    "                                 dtype = 'int',analyzer='word',token_pattern='(?u)\\b\\w\\w+\\b',encoding='utf-8' )\n",
    "        \n",
    "    X = vectorizer.fit_transform(review)\n",
    "    return X,vectorizer\n",
    "    \n",
    "matrix, cv = count_vectorize(review)\n",
    "print ('matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))\n",
    "print('first doc has terms:\\n%s' % (str(sorted(matrix[0].nonzero()[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix1, vec = count_vectorize(review,ngram_range=(1,1))\n",
    "matrix2, vec = count_vectorize(review,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X =np.array(matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vf4,Wf4,Sf4 = rec_train(X,Y,1000,1000,classes,0.001,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YY4=rec_prediction(Wf4,Vf4,Sf4,X,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  0 500]\n",
      " [  0 500]]\n",
      "Accuracy 0.5\n",
      "Precision [nan, 0.5]\n",
      "Recall [0.0, 1.0]\n",
      "F_score [nan, 0.66666666666666663]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,Y,YY4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic():\n",
    "    return LogisticRegression(C=1.0,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - TriGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acuracy through logisteic regression is  0.939\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = logistic()\n",
    "logistic_classifier.fit(matrix, yl)\n",
    "logistic_predictions = logistic_classifier.predict(matrix)\n",
    "print \"The acuracy through logisteic regression is \",accuracy_score(yl, logistic_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - UniGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acuracy through logisteic regression is  0.867\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier.fit(matrix1, yl)\n",
    "logistic_predictions = logistic_classifier.predict(matrix1)\n",
    "print \"The acuracy through logisteic regression is \",accuracy_score(yl, logistic_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - BiGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acuracy through logisteic regression is  0.933\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier.fit(matrix2, yl)\n",
    "logistic_predictions = logistic_classifier.predict(matrix2)\n",
    "print \"The acuracy through logisteic regression is \",accuracy_score(yl, logistic_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
