{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Naive Bayes model - Binarizing the features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.special import comb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the file\n",
    "def readFile(fileName):\n",
    "    with open(fileName,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines_read = readFile('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and transform data section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Split the data into texts and class labels\n",
    "'''\n",
    "\n",
    "def data_process(lines_read):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    xl=[]\n",
    "    for i in range(len(lines_read)):\n",
    "        split = lines_read[i].split()\n",
    "        y.append(int(split[-1]))\n",
    "        x.append(\" \".join ([word.lower() for word in split[0:len(split)-1]]))\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y=data_process(lines_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameter calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    Function description: Calculate the prior alpha for each class\n",
    "\n",
    "'''\n",
    "\n",
    "def find_prior(y):\n",
    "    key = np.unique(y)\n",
    "    prior = [0.0 for i in range(len(key))]\n",
    "    cls_split={i:0 for i in key }\n",
    "    for i in y:\n",
    "        if i in key:\n",
    "            cls_split[i]+=1\n",
    "        else:\n",
    "            cls_split[i]+=1\n",
    "    for i in range(len(cls_split.values())):\n",
    "        prior[i] = 1.*cls_split.values()[i]/len(y)\n",
    "    return prior\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "prior=find_prior(y)\n",
    "print prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Remove non-alphanumeric content from the text \n",
    "'''\n",
    "\n",
    "\n",
    "def stripnonalphanumeric(x):\n",
    "    return re.findall('\\w+',x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Build a dictionary of unique words. The text is tokenized and the occurence of each word is mapped. \n",
    "               In this function, care is taken to remove the stop words which would help in classifying the texts accurately\n",
    "               \n",
    "               Input: Text\n",
    "               Output: unique words in the corpus\n",
    "\n",
    "'''\n",
    "\n",
    "def vocab_builder(x,y):\n",
    "    word = {}\n",
    "    bag_of_words = []\n",
    "    for doc_id in range(0,len(x)):\n",
    "        split_text = stripnonalphanumeric(x[doc_id]) # strip text \n",
    "        for i in split_text:\n",
    "            bag_of_words.append(i)\n",
    "    words =  dict(Counter(bag_of_words)) # word counter \n",
    "    bag_of_words =[]\n",
    "    for i in words:\n",
    "        if words[i] < 50: #remove words \n",
    "            bag_of_words.append(i)\n",
    "    return (bag_of_words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v=vocab_builder(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Create a feature vector for the given texts\n",
    "               Mark the number of times the word appears\n",
    "               \n",
    "               Returns: Feature vetor\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def create_feature_vector(x,c):\n",
    "    f_v = [np.zeros((len(c)),dtype=int) for i in range(len(x))]\n",
    "    feat_vect = []\n",
    "    for i in range(len(x)):\n",
    "        co = Counter(stripnonalphanumeric(x[i]))\n",
    "        for j in x[i].split():\n",
    "            if j in c:\n",
    "                ix=c.index(j)\n",
    "                f_v[i][ix] = co[j]\n",
    "    return [i.tolist() for i in f_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_vector = create_feature_vector(x,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To partition the given data into the respective classes\n",
    "               Input: Feature vector and class labels\n",
    "               Output: Partitioned data\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_partition(feat_vector,y):\n",
    "    zipped =zip(feat_vector,y) #combine feature vector with its class labels\n",
    "    pos_rev=[]\n",
    "    neg_rev=[]\n",
    "    for i in range(len(feat_vector)):\n",
    "        if zipped[i][1] == 1:\n",
    "            pos_rev.append(zipped[i][0]) #putthe data into negative list\n",
    "        else:\n",
    "            neg_rev.append(zipped[i][0]) #putthe data into positive list\n",
    "    return pos_rev,neg_rev\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos,neg = data_partition(feat_vector,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To calulate the parameter alpha(j|y=i), where j is the jth word in the sentence and i is the class label\n",
    "               Input: segregated data bases on the class label\n",
    "               \n",
    "               Output: Parameters of the distribution\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def calculate_parameter(pos,neg):\n",
    "    eps=0.5 # for smoothing\n",
    "    labels = np.unique(y)\n",
    "    alpha={}\n",
    "    P = np.sum(pos) # total no. of words in positive class\n",
    "    N = np.sum(neg) # total no. of words in negative class\n",
    "    alpha_pos = (np.sum(pos,axis=0)+eps)/((len(pos)*P)+len(labels)*eps)  #positive parameters\n",
    "    alpha_neg = ((np.sum(neg,axis=0))+eps)/((len(neg)*N)+len(labels)*eps) #negative parameters\n",
    "    alpha[labels[0]] = alpha_neg\n",
    "    alpha[labels[1]] =alpha_pos\n",
    "    return alpha # dictionary containing both alphas\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([  3.28191449e-07,   3.28191449e-07,   3.28191449e-07, ...,\n",
      "         9.84574346e-07,   3.28191449e-07,   2.95372304e-06]), 1: array([  2.80819837e-07,   2.80819837e-07,   8.42459510e-07, ...,\n",
      "         2.80819837e-07,   8.42459510e-07,   2.52737853e-06])}\n"
     ]
    }
   ],
   "source": [
    "alpha=calculate_parameter(pos,neg)\n",
    "print alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funtion desc: Membership funtion, whih provides the membership values for each class\n",
    "              Input: 1) sample to be predicted\n",
    "                     2) Model parameters\n",
    "                     3) Prior probability\n",
    "                     \n",
    "        Output: Membership values for each class\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def g_x(x,alpha,prior):\n",
    "    d=[]\n",
    "    P = np.sum(x) #total number words in the corpus\n",
    "    for i in alpha:\n",
    "        p=0\n",
    "        l_t1 = 0\n",
    "        for j in range(len(x)):\n",
    "            l_t1 += np.log(comb(P,x[j])*(alpha[i][j]**x[j])*((1-alpha[i][j])**(P-x[j]))) # using the formula\n",
    "        p=l_t1+prior[i]\n",
    "        d.append(p)\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funtion description: Predict the class labels of the supplied sample. \n",
    "                     Call the membership function for each sample on the classes and find the maximum value, which \n",
    "                     gives the class of the particular sample.\n",
    "                     \n",
    "                     Input: Samples(x) and True class labels(y)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def predict_labels(x,y):\n",
    "    predicted=[]\n",
    "    cls=np.unique(y)\n",
    "    g = []\n",
    "    for i in x:\n",
    "        g.append(g_x(i,alpha,prior))  #call membership funtction for each sample\n",
    "    for i in g:\n",
    "        predicted.append(cls[i.index(max(i))]) #get the max value's index and get the corresponding class\n",
    "    return predicted\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = predict_labels(feat_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To calculate the model parameters suh as precision, recall and f-measure from the confusion-matrix\n",
    "Inuput: Actual and predicted values\n",
    "Output: model parameters\n",
    "\n",
    "\n",
    "Classification accuracy\n",
    "(TP + TN) / (TP + TN + FP + FN)\n",
    "Error rate\n",
    "(FP + FN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision: (or Positive predictive value)\n",
    "proportion of predicted positives which\n",
    "are actual positive\n",
    "TP / (TP + FP)\n",
    "Recall: proportion of actual positives\n",
    "which are predicted positive\n",
    "TP / (TP + FN)\n",
    "\n",
    "Error rate: 1- classification accuracy\n",
    "\n",
    "'''\n",
    "\n",
    "def model_eval(actual,predicted):\n",
    "    Truth= pd.Series(actual,name = 'Truth' )\n",
    "    Predicted = pd.Series(predicted,name='Predicted')\n",
    "    confusion_matrix = pd.crosstab(Truth, Predicted)\n",
    "    arr_cm = confusion_matrix.as_matrix()\n",
    "    diag = arr_cm.diagonal() \n",
    "    accuracy = float(sum(diag))/np.sum(arr_cm)\n",
    "    precision = np.divide(diag,1.0*(np.sum(arr_cm,axis=0)))\n",
    "    recall = np.divide(diag,1.0*(np.sum(arr_cm,axis=1)))\n",
    "    fmeasure = 2*((precision * recall)/(precision + recall))\n",
    "    return confusion_matrix,accuracy,precision,recall,fmeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function to perform 10-fold cross validation. In this method the test and train indices are split using using the inbuit\n",
    "   'KFold' function.\n",
    "    Calculation of parameters is done namely (prior and likelihood) for each of the train set\n",
    "    With the model parameters the modelis tested on the test data\n",
    "    Model parameters such as precision,reall,accuracy and error rate is calculated\n",
    "    Input 1: 'x' \n",
    "    Input 2: True predicted values\n",
    "    Input 3: No of folds (10 by default)\n",
    "\n",
    "    Output: Predicted values, Model parameters \n",
    "'''\n",
    "def x_fold_validation(x,y,nfolds=10):\n",
    "    confusion_matrix_list=[]\n",
    "    accuracy_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    fmeasure_list=[]\n",
    "    y=np.array(y)\n",
    "    x=np.array(x)\n",
    "    cv = KFold(len(y), nfolds,shuffle=True,random_state=23) #inbuilt function to split the indices\n",
    "    for train_idx, test_idx in cv:\n",
    "        prior = find_prior(y[train_idx])\n",
    "        pos,neg = data_partition(x[train_idx],y[train_idx])\n",
    "        alfa = calculate_parameter(pos,neg)\n",
    "        predict = predict_labels(x[test_idx],y[test_idx])\n",
    "        conf_matrix,accuracy,precision,recall,fmeasure = model_eval(y[test_idx].tolist(),predict)\n",
    "        print conf_matrix\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "        accuracy_list.append(accuracy.tolist())\n",
    "        precision_list.append(precision.tolist())\n",
    "        recall_list.append(recall.tolist())\n",
    "        fmeasure_list.append(fmeasure.tolist())\n",
    "    print '################################'\n",
    "    print 'Average of the model parameters'\n",
    "    print '################################'\n",
    "    print 'Error rate:', (1-np.mean(accuracy_list,axis=0))\n",
    "    print 'Accuracy:',np.mean(accuracy_list)\n",
    "    print 'Precision:', np.mean(precision_list,axis=0)\n",
    "    print 'Recall:', np.mean(recall_list,axis=0)\n",
    "    print 'F-measure:', np.mean(fmeasure_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1\n",
      "Truth            \n",
      "0          49   3\n",
      "1           1  47\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          45   0\n",
      "1           4  51\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          40   4\n",
      "1           2  54\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          46   2\n",
      "1           4  48\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          52   2\n",
      "1           5  41\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          49   1\n",
      "1           8  42\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          56   1\n",
      "1           2  41\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          44   4\n",
      "1           2  50\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          47   1\n",
      "1           4  48\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          53   1\n",
      "1           7  39\n",
      "################################\n",
      "Average of the model parameters\n",
      "################################\n",
      "Error rate: 0.058\n",
      "Accuracy: 0.942\n",
      "Precision: [ 0.92696191  0.96179753]\n",
      "Recall: [ 0.96124659  0.92110362]\n",
      "F-measure: [ 0.94294667  0.94001407]\n"
     ]
    }
   ],
   "source": [
    "x_fold_validation(feat_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
