{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import datasets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: load the data \n",
    "returns: numpy array containing all features and classes (Iris-versicolor and Iris-virginica)\n",
    "'''\n",
    "def load_data():\n",
    "    data_file = open(\"C:\\Users\\GURU\\Desktop\\Machine Learning-Asg\\Natarajan_Guru Prasad_Ass3\\Dataset\\Image_data.txt\", 'r')\n",
    "    read_data = data_file.readlines()\n",
    "    data_file.close()\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(data) :   \n",
    "    i=[]\n",
    "    y=[]\n",
    "    classes = ['brickface', 'sky', 'foliage', 'cement', 'window', 'path', 'grass']\n",
    "    for d in data:\n",
    "            dt = d.split(',')\n",
    "            ip = (np.asfarray(dt[1:]))\n",
    "            lab= classes.index(dt[0].lower())\n",
    "            i.append(ip)\n",
    "            y.append(lab)\n",
    "    x= np.divide(i,np.sum(i,axis=0))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y=prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function descriotion: Function to initialize the network parameters\n",
    "\n",
    "'''\n",
    "\n",
    "def build_MLP(iunits, hunits, ounits):\n",
    "    w = np.random.normal(0.1,0.5, (hunits, iunits)) #Different distributions to initialize weights\n",
    "    v = np.random.normal(0.1,0.5, (ounits, hunits))  #Different distributions to initialize weights\n",
    "    return w,v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing the network with number of input units, output units and hidden units\n",
    "iunits = np.shape(x)[1]\n",
    "ounits = len(np.unique(y))\n",
    "hunits = int(math.ceil((iunits+ounits)/2))\n",
    "w,v=build_MLP(iunits,hunits,ounits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function Desc: Calculte softmax function\n",
    "\n",
    "'''\n",
    "def softmax(ip):\n",
    "    deno=np.sum(np.exp(ip))\n",
    "    return np.array(np.exp(ip)/deno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function Desc: Calculte sigmoid function\n",
    "\n",
    "'''\n",
    "def sigmoid(ip):\n",
    "    return 1./(1.+np.exp(-ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function Desc: Update the parameters\n",
    "\n",
    "'''\n",
    "def update_params(w,v,ip, op,step):\n",
    "    beta = 0.2\n",
    "    ip = np.array(ip, ndmin=2).T #convert thr input into two dimensional data\n",
    "    yhats = np.array(op, ndmin=2).T #convert thr output into two dimensional data\n",
    "    hunit_ip = np.dot(w, ip) #weighted inputs\n",
    "    hunit_op = sigmoid(hunit_ip) #calculate 'z' hidden unit output using sigmoid funtion\n",
    "    ounit_ip = np.dot(v, hunit_op) #weighted outputs\n",
    "    ounit_op = softmax(ounit_ip) # calculate 'yhat using softmax funtion\n",
    "    error = ounit_op - yhats #calculate error \n",
    "    v -= step * np.dot(error, np.transpose(hunit_op)) #update v\n",
    "    curr_w=w\n",
    "    if whist:\n",
    "        prev_w = whist[-1]\n",
    "    else:\n",
    "        prev_w = curr_w\n",
    "    w -= (step * (np.dot((np.dot(v.T, error)  * hunit_op * (1.0 - hunit_op)), np.transpose(ip))))+beta*(curr_w-prev_w) #update w\n",
    "    whist.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "no_iterations = 3000\n",
    "step_size = 5.0\n",
    "whist=[]\n",
    "for it in range(no_iterations):\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        yhats = np.zeros(ounits)\n",
    "        yhats[int(y[i])] = 1\n",
    "        update_params(w,v,x[i],yhats,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function Desc: Predict the labels of the test samples. This function is similar to update_params, the only difference \n",
    "is weights will not be updated\n",
    "\n",
    "'''\n",
    "def predict(ip):\n",
    "    ip = np.array(ip, ndmin=2).T\n",
    "    hunit_ip = np.dot(w, ip)\n",
    "    hunit_op = sigmoid(hunit_ip)\n",
    "    ounit_ip = np.dot(v, hunit_op)\n",
    "    predicts = softmax(ounit_ip)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in range(np.shape(x)[0]):\n",
    "    op=predict(x[i])\n",
    "    pred = np.argmax(op)\n",
    "    if y[i] == pred:\n",
    "        k+=1\n",
    "print  1.0*k/np.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To calculate the model parameters suh as precision, recall and f-measure from the confusion-matrix\n",
    "Inuput: Actual and predicted values\n",
    "Output: model parameters\n",
    "\n",
    "\n",
    "Classification accuracy\n",
    "(TP + TN) / (TP + TN + FP + FN)\n",
    "Error rate\n",
    "(FP + FN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision: (or Positive predictive value)\n",
    "proportion of predicted positives which\n",
    "are actual positive\n",
    "TP / (TP + FP)\n",
    "Recall: proportion of actual positives\n",
    "which are predicted positive\n",
    "TP / (TP + FN)\n",
    "\n",
    "'''\n",
    "\n",
    "def model_eval(actual,predicted):\n",
    "    Truth= pd.Series(actual,name = 'Truth' )\n",
    "    Predicted = pd.Series(predicted,name='Predicted')\n",
    "    confusion_matrix = pd.crosstab(Truth, Predicted)\n",
    "    arr_cm = confusion_matrix.as_matrix()\n",
    "    diag = arr_cm.diagonal()\n",
    "    accuracy = float(sum(diag))/np.sum(arr_cm)\n",
    "    precision = np.divide(diag,1.0*(np.sum(arr_cm,axis=0))) \n",
    "    recall = np.divide(diag,1.0*(np.sum(arr_cm,axis=0)))\n",
    "    fmeasure = 2*((precision * recall)/(precision + recall))\n",
    "    return confusion_matrix,accuracy,precision,recall,fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Function to perform 10-fold cross validation. In this method the test and traparams in indices are split using using the inbuit\n",
    "   'KFold' function.\n",
    "    Input 1: 'x' \n",
    "    Input 2: True predicted values\n",
    "    Input 3: No of folds (10 by default)\n",
    "    \n",
    "    Performance measures such as accuracy, precision, f-measure\n",
    "'''\n",
    "\n",
    "def x_fold_validation(x,y,nfolds=5,shuffle=True,random_state=23):\n",
    "    confusion_matrix_list=[]\n",
    "    accuracy_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    fmeasure_list=[]\n",
    "    mom_wei=[]\n",
    "    step_size = 1.0\n",
    "    cv = KFold(len(y), nfolds,shuffle=True,random_state=23) #inbuilt function to split the indices\n",
    "    for train_idx, test_idx in cv:\n",
    "        x_train = x[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        x_test = x[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "        for it in range(500):\n",
    "            for i in xrange(len(x_train)) :\n",
    "                yhats = np.zeros(len(np.unique(y)))\n",
    "                yhats[int(y_train[i])] = 1\n",
    "                update_params(w,v,x_train[i],yhats,step_size)\n",
    "            pred=[]\n",
    "        for i in x_test:\n",
    "            outputs = predict(i)\n",
    "            label = np.argmax(outputs)\n",
    "            pred.append(label)\n",
    "        conf_matrix,accuracy,precision,recall,fmeasure = model_eval(y_test.tolist(),pred)\n",
    "        print conf_matrix\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision.tolist())\n",
    "        recall_list.append(recall.tolist())\n",
    "        fmeasure_list.append(fmeasure.tolist())\n",
    "    print '################################'\n",
    "    print 'Average of the model parameters'\n",
    "    print '################################'\n",
    "    print 'Error rate:', 1- np.mean(accuracy_list)\n",
    "    print 'Accuracy:', np.mean(accuracy_list) \n",
    "    print 'Precision:', np.mean(precision_list,axis=0)\n",
    "    print 'Recall:', np.mean(recall_list,axis=0)\n",
    "    print 'F-measure:', np.mean(fmeasure_list,axis=0)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0  1   2  3  4  5   6\n",
      "Truth                           \n",
      "0          4  0   0  0  0  0   0\n",
      "1          0  8   0  0  0  0   0\n",
      "2          0  0  12  0  0  0   0\n",
      "3          0  0   0  4  0  0   0\n",
      "4          0  0   0  0  3  0   0\n",
      "5          0  0   0  0  0  1   0\n",
      "6          0  0   0  0  0  0  10\n",
      "Predicted  0  1  2  3  4  5  6\n",
      "Truth                         \n",
      "0          6  0  0  0  0  0  0\n",
      "1          0  4  0  0  0  0  0\n",
      "2          0  0  3  0  0  0  0\n",
      "3          0  0  0  7  0  0  0\n",
      "4          0  0  0  0  9  0  0\n",
      "5          0  0  0  0  0  9  0\n",
      "6          0  0  0  0  0  0  4\n",
      "Predicted  0  1  2  3   4  5  6\n",
      "Truth                          \n",
      "0          5  0  0  0   0  0  0\n",
      "1          0  4  0  0   0  0  0\n",
      "2          0  0  4  0   0  0  0\n",
      "3          0  0  0  9   0  0  0\n",
      "4          0  0  0  0  10  0  0\n",
      "5          0  0  0  0   0  7  0\n",
      "6          0  0  0  0   0  0  3\n",
      "Predicted  0  1  2  3  4  5  6\n",
      "Truth                         \n",
      "0          9  0  0  0  0  0  0\n",
      "1          0  4  0  0  0  0  0\n",
      "2          0  0  7  0  0  0  0\n",
      "3          0  0  0  5  0  0  0\n",
      "4          0  0  0  0  3  0  0\n",
      "5          0  0  0  0  0  8  0\n",
      "6          0  0  0  0  0  0  6\n",
      "Predicted  0   1  2  3  4  5  6\n",
      "Truth                          \n",
      "0          6   0  0  0  0  0  0\n",
      "1          0  10  0  0  0  0  0\n",
      "2          0   0  4  0  0  0  0\n",
      "3          0   0  0  5  0  0  0\n",
      "4          0   0  0  0  5  0  0\n",
      "5          0   0  0  0  0  5  0\n",
      "6          0   0  0  0  0  0  7\n",
      "################################\n",
      "Average of the model parameters\n",
      "################################\n",
      "Error rate: 0.0\n",
      "Accuracy: 1.0\n",
      "Precision: [ 1.  1.  1.  1.  1.  1.  1.]\n",
      "Recall: [ 1.  1.  1.  1.  1.  1.  1.]\n",
      "F-measure: [ 1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "x_fold_validation(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
