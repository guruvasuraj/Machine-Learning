{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the file\n",
    "def readFile(fileName):\n",
    "    with open(fileName,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines_read = readFile('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Split the data into texts and class labels\n",
    "'''\n",
    "\n",
    "def data_process(lines_read):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    xl=[]\n",
    "    for i in range(len(lines_read)):\n",
    "        split = lines_read[i].split()\n",
    "        y.append(int(split[-1]))\n",
    "        x.append(\" \".join ([word.lower() for word in split[0:len(split)-1]]))\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y=data_process(lines_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Calculate the prior alpha of the classes.\n",
    "    \n",
    "'''\n",
    "\n",
    "def find_prior(y):\n",
    "    key = np.unique(y)\n",
    "    prior = [0.0 for i in range(len(key))]\n",
    "    cls_split={i:0 for i in key }\n",
    "    for i in y:\n",
    "        if i in key:\n",
    "            cls_split[i]+=1\n",
    "        else:\n",
    "            cls_split[i]+=1\n",
    "    for i in range(len(cls_split.values())):\n",
    "        prior[i] = 1.*cls_split.values()[i]/len(y)\n",
    "    return prior\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "prior=find_prior(y)\n",
    "print prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Remove non-alphanumeric content from the text \n",
    "'''\n",
    "\n",
    "def stripnonalphanumeric(x):\n",
    "    return re.findall('\\w+',x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Build a dictionary of unique words. The text is tokenized. \n",
    "               \n",
    "               Input: Text\n",
    "               Output: unique words in the corpus\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def vocab_builder(x,y):\n",
    "    bag_of_words = []\n",
    "    for doc_id in range(0,len(x)):\n",
    "        split_text=stripnonalphanumeric(x[doc_id])\n",
    "        for w in split_text:\n",
    "            if w not in bag_of_words:\n",
    "                bag_of_words.append(w)\n",
    "    return bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v=vocab_builder(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: Create a feature vector for the given texts:\n",
    "               Mark '1' if the word is present else '0' if not present\n",
    "               \n",
    "               Returns: Feature vetor\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def create_feature_vector(x,y,c):\n",
    "    f_v = [np.zeros((len(c)),dtype=int) for i in range(len(x))]\n",
    "    feat_vect = []\n",
    "    for i in range(len(x)):\n",
    "        for j in x[i].split():\n",
    "            if j in c:\n",
    "                ix=c.index(j)\n",
    "                f_v[i][ix] = 1\n",
    "    return [i.tolist() for i in f_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_vector = create_feature_vector(x,y,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To partition the given data into the respective classes\n",
    "               Input: Feature vector and class labels\n",
    "               Output: Partitioned data\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def data_partition(feat_vector,y):\n",
    "    zipped =zip(feat_vector,y) #combine feature vector with its class labels\n",
    "    pos_rev=[]\n",
    "    neg_rev=[]\n",
    "    for i in range(len(feat_vector)):\n",
    "        if zipped[i][1] == 1:\n",
    "            pos_rev.append(zipped[i][0]) #put the data into positive list\n",
    "        else:\n",
    "            neg_rev.append(zipped[i][0])#put the data into negative list\n",
    "    return pos_rev,neg_rev\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos,neg = data_partition(feat_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funtion desc: Membership funtion, whih provides the membership values for each class\n",
    "              Input: 1) sample to be predicted\n",
    "                     2) Model parameters\n",
    "                     3) Prior probability\n",
    "                     \n",
    "        Output: Membership values for each class\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def calculate_parameter(pos,neg):\n",
    "    eps = 1.0 #for smoothing\n",
    "    labels = np.unique(y) #unique labels of class y\n",
    "    alpha={}\n",
    "    alpha_pos = ((np.sum(pos,axis=0))+eps)/(len(pos)+2*eps) # positive alpha \n",
    "    alpha_neg = ((np.sum(neg,axis=0))+eps)/(len(neg)+2*eps) #negative alpha\n",
    "    alpha[labels[0]] = alpha_neg\n",
    "    alpha[labels[1]] =alpha_pos\n",
    "    return alpha #dictionary of both alphas\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 0.28685259,  0.05976096,  0.00796813, ...,  0.00398406,\n",
      "        0.00398406,  0.00398406]), 1: array([ 0.38844622,  0.05776892,  0.00199203, ...,  0.00199203,\n",
      "        0.00199203,  0.00199203])}\n"
     ]
    }
   ],
   "source": [
    "alpha=calculate_parameter(pos,neg)\n",
    "print alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funtion desc: Membership funtion, whih provides the membership values for each class\n",
    "              Input: 1) sample to be predicted\n",
    "                     2) Model parameters\n",
    "                     3) Prior probability\n",
    "                     \n",
    "        Output: Membership values for each class\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def g_x(x,alpha,prior):\n",
    "    d=[]\n",
    "    for i in alpha:\n",
    "        p=0\n",
    "        l_t1 = 0\n",
    "        for j in range(len(x)):\n",
    "            if x[j] == 1:\n",
    "                l_t1 += np.log(alpha[i][j]) #if word is present multiply with alpha\n",
    "            else:\n",
    "                l_t1 += np.log(abs(1-alpha[i][j])) # if word not present multiply with 1-alpha\n",
    "        p=l_t1+np.log(prior[i])\n",
    "        d.append(p)\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Funtion description: Predict the class labels of the supplied sample. \n",
    "                     Call the membership function for each sample on the classes and find the maximum value, which \n",
    "                     gives the class of the particular sample.\n",
    "                     \n",
    "                     Input: Samples(x) and True class labels(y)\n",
    "\n",
    "'''\n",
    "\n",
    "def predict_labels(x,y):\n",
    "    predicted=[]\n",
    "    cls=np.unique(y)\n",
    "    g = []\n",
    "    for i in x:\n",
    "        g.append(g_x(i,alpha,prior)) #callmembership funtction for each sample\n",
    "    for i in g:\n",
    "        predicted.append(cls[i.index(max(i))]) #get the max value's index and get the corresponding class \n",
    "    return predicted\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = predict_labels(feat_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function desc: To calculate the model parameters suh as precision, recall and f-measure from the confusion-matrix\n",
    "Inuput: Actual and predicted values\n",
    "Output: model parameters\n",
    "\n",
    "Classification accuracy\n",
    "(TP + TN) / (TP + TN + FP + FN)\n",
    "Error rate\n",
    "(FP + FN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision: (or Positive predictive value)\n",
    "proportion of predicted positives which\n",
    "are actual positive\n",
    "TP / (TP + FP)\n",
    "Recall: proportion of actual positives\n",
    "which are predicted positive\n",
    "TP / (TP + FN)\n",
    "\n",
    "Error rate: 1- classification accuracy\n",
    "\n",
    "'''\n",
    "\n",
    "def model_eval(actual,predicted):\n",
    "    Truth= pd.Series(actual,name = 'Truth' )\n",
    "    Predicted = pd.Series(predicted,name='Predicted')\n",
    "    confusion_matrix = pd.crosstab(Truth, Predicted)\n",
    "    print confusion_matrix\n",
    "    arr_cm = confusion_matrix.as_matrix()\n",
    "    diag = arr_cm.diagonal()\n",
    "    accuracy = float(sum(diag))/np.sum(arr_cm)\n",
    "    precision = np.divide(diag,1.0*(np.sum(arr_cm,axis=0)))\n",
    "    recall = np.divide(diag,1.0*(np.sum(arr_cm,axis=1)))\n",
    "    fmeasure = 2*((precision * recall)/(precision + recall))\n",
    "    return confusion_matrix,accuracy,precision,recall,fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function to perform 10-fold cross validation. In this method the test and train indices are split using using the inbuit\n",
    "   'KFold' function.\n",
    "    Calculation of parameters is done namely (prior and posterior) for each of the train set\n",
    "    With the model parameters the modelis tested on the test data\n",
    "    Model parameters such as precision,reall,accuracy and error rate is calculated\n",
    "    \n",
    "    Input 1: 'x' \n",
    "    Input 2: True predicted values\n",
    "    Input 3: No of folds (10 by default)\n",
    "    \n",
    "    Output: Predicted values, Model parameters \n",
    " \n",
    "'''\n",
    "def x_fold_validation(x,y,nfolds=10):\n",
    "    confusion_matrix_list=[]\n",
    "    accuracy_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    fmeasure_list=[]\n",
    "    y=np.array(y)\n",
    "    x=np.array(x)\n",
    "    cv = KFold(len(y), nfolds,shuffle=True,random_state=23) #inbuilt function to split the indices\n",
    "    for train_idx, test_idx in cv:\n",
    "        prior = find_prior(y[train_idx])\n",
    "        pos,neg = data_partition(x[train_idx],y[train_idx])\n",
    "        alfa = calculate_parameter(pos,neg)\n",
    "        predict = predict_labels(x[test_idx],y[test_idx])\n",
    "        conf_matrix,accuracy,precision,recall,fmeasure = model_eval(y[test_idx].tolist(),predict)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "        accuracy_list.append(accuracy.tolist())\n",
    "        precision_list.append(precision.tolist())\n",
    "        recall_list.append(recall.tolist())\n",
    "        fmeasure_list.append(fmeasure.tolist())\n",
    "    print '################################'\n",
    "    print 'Average of the model parameters'\n",
    "    print '################################'\n",
    "    print 'Error rate:', (1-np.mean(accuracy_list,axis=0))\n",
    "    print 'Accuracy:',np.mean(accuracy_list)\n",
    "    print 'Precision:', np.mean(precision_list,axis=0)\n",
    "    print 'Recall:', np.mean(recall_list,axis=0)\n",
    "    print 'F-measure:', np.mean(fmeasure_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1\n",
      "Truth            \n",
      "0          50   2\n",
      "1           6  42\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          45   0\n",
      "1           7  48\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          43   1\n",
      "1           7  49\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          47   1\n",
      "1          12  40\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          53   1\n",
      "1           9  37\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          50   0\n",
      "1          15  35\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          57   0\n",
      "1           6  37\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          47   1\n",
      "1           5  47\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          47   1\n",
      "1           9  43\n",
      "Predicted   0   1\n",
      "Truth            \n",
      "0          54   0\n",
      "1          10  36\n",
      "################################\n",
      "Average of the model parameters\n",
      "################################\n",
      "Error rate: 0.093\n",
      "Accuracy: 0.907\n",
      "Precision: [ 0.85305652  0.98402788]\n",
      "Recall: [ 0.98577927  0.82701489]\n",
      "F-measure: [ 0.9139618   0.89731896]\n"
     ]
    }
   ],
   "source": [
    "x_fold_validation(feat_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
